\section{Team}

\subsection*{Deliverable 3 - Initial Setup}

This part deals with camera calibration for the drone, specifically obtaining the intrinsic matrix and distortion coefficients. The goal is to transform detected pixel coordinates into undistorted 3D bearing vectors that can be used for geometric vision tasks.

The implementation resides in the function \lstinline{calibrateKeypoints}. It takes two sets of 2D keypoints and converts them into normalized bearing vectors using the camera parameters. Hereâ€™s what the code does:

\begin{minted}{cpp}
void calibrateKeypoints(
  const std::vector<cv::Point2f>& pts1,
  const std::vector<cv::Point2f>& pts2,
  opengv::bearingVectors_t& bearing_vector_1,
  opengv::bearingVectors_t& bearing_vector_2
) {
  std::vector<cv::Point2f> points1_rect, points2_rect;
  cv::undistortPoints(
    pts1, points1_rect,
    camera_params_.K, camera_params_.D
  );
  cv::undistortPoints(
    pts2, points2_rect,
    camera_params_.K, camera_params_.D
  );

  for (auto const& pt: points1_rect){
    opengv::bearingVector_t bearing_vector(pt.x, pt.y, 1);
    bearing_vector_1.push_back(bearing_vector.normalized());
  }

  for (auto const& pt: points2_rect){
    opengv::bearingVector_t bearing_vector(pt.x, pt.y, 1);
    bearing_vector_2.push_back(bearing_vector.normalized());
  }
}
\end{minted}

After undistorting the points with \lstinline{cv::undistortPoints}, each corrected 2D point $(x, y)$ is lifted to a 3D direction vector $(x, y, 1)$. Since the intrinsic matrix has already been accounted for during undistortion, the effective focal length becomes 1, and the resulting vectors are normalized to unit length.

This function is called inside \lstinline{cameraCallback} with a single line:

\begin{minted}{cpp}
calibrateKeypoints(
  pts1, pts2,
  bearing_vector_1, bearing_vector_2
);
\end{minted}

Once populated, \lstinline{bearing_vector_1} and \lstinline{bearing_vector_2} are passed to an OpenGV adapter:

\begin{minted}{cpp}
Adapter adapter_mono(
  bearing_vector_1,
  bearing_vector_2
);
\end{minted}

This prepares the data for the RANSAC-based relative pose estimation that follows.



